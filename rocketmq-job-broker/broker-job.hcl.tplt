job "${job-name}" {
  datacenters = ["${region}"]
  region = "${region}"
  constraint {
    attribute = "$${node.class}"
    value = "${node-class}"
  }
  constraint {
    attribute = "$${meta.az}"
    operator = "distinct_property"
    value = "${task-limit-per-az}"
  }
  group "broker" {
    count = 3
    spread {
      attribute = "$${meta.az}"
    }
    update {
      max_parallel = 1
      health_check = "checks"
      min_healthy_time = "1m"
      healthy_deadline = "5m"
      progress_deadline = "24h"
    }
    migrate {
      max_parallel = 1
      health_check = "checks"
      min_healthy_time = "1m"
    }
    ephemeral_disk {
      migrate = true
      size = "500"
      sticky = true
    }
    task "broker" {
      driver = "docker"
      //to use volume on host, we use root user inside container
      user = "0"
      config {
        privileged = true
        image = "${broker-image}"
        command = "./mqbroker"
        args = [
          "-c",
          "/opt/rocketmq-${rockermq-version}/conf/dledger/broker.conf"
        ]
        volumes = [
          "local/conf:/opt/rocketmq-${rockermq-version}/conf/dledger",
          "local/data:/data",
        ]
        network_mode = "host"
      }
      resources {
        cpu = ${cpu}
        memory = ${memory}
        network {
          port "broker" {}
          port "dledger" {}
        }
      }
      service {
        port = "broker"
        check {
          type = "tcp"
          port = "broker"
          interval = "10s"
          timeout = "2s"
        }
      }
      meta {
        clusterId = "${cluster-id}"
        namesrvCount = "3"
        brokerCount = "3"
        internal = "${internal}"
      }
      template {
        data = <<EOF
        brokerClusterName = {{ env "NOMAD_META_clusterId" }}
        brokerName=broker-{{env "NOMAD_META_clusterId"}}
        {{$internal := env "NOMAD_META_internal"}}
        {{if ne $internal ""}}
          brokerIP1={{env "meta.hostIp"}}
        {{else}}
          {{$allocId := env "NOMAD_ALLOC_INDEX"}}
          brokerIP1={{key (printf "brokerEip/${cluster-id}/eip/%s" $allocId)}}
        {{end}}
        listenPort={{ env "NOMAD_PORT_broker" }}
        namesrvAddr={{range $i := loop ((env "NOMAD_META_namesrvCount")|parseInt)}}{{if ne $i 0}};{{end}}localhost:{{env (printf "NOMAD_PORT_outboundProxy_namesvrTcp%d" $i)}}{{end}}
        storePathRootDir=/data
        storePathCommitLog=/data/commitlog
        enableDLegerCommitLog=true
        dLegerGroup={{ env "NOMAD_META_clusterId" }}
        dLegerPeers={{range $i := loop ((env "NOMAD_META_brokerCount")|parseInt)}}{{$index := (env "NOMAD_ALLOC_INDEX")|parseInt}}{{if ne $i 0}};{{end}}n{{$i}}-{{if ne $i $index}}localhost:{{env (printf "NOMAD_PORT_outboundProxy_dledger%d" $i)}}{{else}}{{env "NOMAD_ADDR_dledger"}}{{end}}{{end}}
        ## must be unique
        dLegerSelfId=n{{ env "NOMAD_ALLOC_INDEX" }}
        sendMessageThreadPoolNums=16
        clientCloseSocketIfTimeout=true
        flushDiskType=ASYNC_FLUSH
EOF
        destination = "local/conf/broker.conf"
        change_mode = "noop"
      }
      template {
        //due to rocketmq set MAX_POSSIBLE_HEAP to MAX_POSSIBLE_RAM / 4, we set half memory to heap, half to direct memory
                //memory im MB * 1024 * 1024 / 2 = memory * 524288
        data = "MAX_POSSIBLE_HEAP=\"{{ multiply ${memory} 930000}}\""
        destination = "local/conf/heapLimit.cfg"
        env = true
      }
    }
    task "terraform" {
      driver = "docker"
      config {
        image = "${terraform-image}"
        command = "sh"
        args = ["/tf/tf.sh"]
        volumes = [
          "local/tf:/tf",
          "/plugin:/plugin",
        ]
        network_mode = "host"
      }
      resources {
        cpu = 100
        memory = 100
      }
      template {
        data = <<EOF
        cd /tf
        cat main.tf
        terraform init -plugin-dir=/plugin
        while true; do
          terraform apply --auto-approve -lock=false
          if [ $? -eq 0 ]; then
            break
          fi
        done

        tail -f /dev/null
        EOF
        destination = "local/tf/tf.sh"
        change_mode = "noop"
      }
      template {
        data = <<EOF
        TF_VAR_ucloud_pub_key=${ucloud_pub_key}
        TF_VAR_ucloud_secret=${ucloud_secret}
        TF_VAR_project_id=${project_id}
        TF_VAR_region=${region}
        TF_VAR_ucloud_api_base_url=${ucloud_api_base_url}
        EOF
        destination = "local/tf/broker.terraform.tfvars"
        env = true
      }
      template {
        data = <<EOF
            variable ucloud_pub_key {}
            variable ucloud_secret {}
            variable project_id {}
            variable region {}
            variable ucloud_api_base_url {}

            terraform {
              backend "consul" {
                address = "{{with service "consul"}}{{with index . 0}}{{.Address}}:8500{{end}}{{end}}"
                scheme = "http"
                path = "brokerEip/${cluster-id}/eip_association/{{ env "NOMAD_ALLOC_INDEX" }}"
              }
            }

            provider "ucloud" {
              public_key = var.ucloud_pub_key
              private_key = var.ucloud_secret
              project_id = var.project_id
              region = var.region
              base_url = var.ucloud_api_base_url
            }

            resource "ucloud_eip_association" "association-{{ env "NOMAD_ALLOC_INDEX" }}" {
              {{$allocId := env "NOMAD_ALLOC_INDEX"}}
              eip_id      = "{{key (printf "brokerEip/${cluster-id}/eipId/%s" $allocId)}}"
              resource_id = "{{env "node.unique.name"}}"
            }
            EOF
        destination = "local/tf/main.tf"
        change_mode = "noop"
      }
    }
    task "inboundProxy" {
      driver = "exec"
      config {
        command = "consul"
        args = [
          "connect",
          "proxy",
          "-service",
          "${brokersvc-name}$${NOMAD_ALLOC_INDEX}",
          "-service-addr",
          "$${NOMAD_ADDR_broker_dledger}",
          "-listen",
          ":$${NOMAD_PORT_tcp}",
          "-register",
        ]
      }
      resources {
        cpu = 500
        memory = 100
        network {
          port "tcp" {}
        }
      }
    }
    task "outboundProxy" {
      driver = "exec"
      config {
        command = "consul"
        args = [
          "connect",
          "proxy",
          "-service",
          "namesvc-sidecar-${cluster-id}-$${NOMAD_ALLOC_INDEX}-0",
          "-upstream",
          "namesvc-${namesvr_clusterId}-0:$${NOMAD_PORT_namesvrTcp0}",
          "-service",
          "namesvc-sidecar-${cluster-id}-$${NOMAD_ALLOC_INDEX}-1",
          "-upstream",
          "namesvc-${namesvr_clusterId}-1:$${NOMAD_PORT_namesvrTcp1}",
          "-service",
          "namesvc-sidecar-${cluster-id}-$${NOMAD_ALLOC_INDEX}-2",
          "-upstream",
          "namesvc-${namesvr_clusterId}-2:$${NOMAD_PORT_namesvrTcp2}",
          "-service",
          "broker-dledger-sidecar-${cluster-id}-$${NOMAD_ALLOC_INDEX}-0",
          "-upstream",
          "${brokersvc-name}0:$${NOMAD_PORT_dledger0}",
          "-service",
          "broker-dledger-sidecar-${cluster-id}-$${NOMAD_ALLOC_INDEX}-1",
          "-upstream",
          "${brokersvc-name}1:$${NOMAD_PORT_dledger1}",
          "-service",
          "broker-dledger-sidecar-${cluster-id}-$${NOMAD_ALLOC_INDEX}-2",
          "-upstream",
          "${brokersvc-name}2:$${NOMAD_PORT_dledger2}",
        ]
      }
      resources {
        cpu = 2000
        memory = 500
        network {
          port "namesvrTcp0" {}
          port "namesvrTcp1" {}
          port "namesvrTcp2" {}
          port "dledger0" {}
          port "dledger1" {}
          port "dledger2" {}
        }
      }
    }
  }
  reschedule {
    delay          = "30s"
    delay_function = "exponential"
    max_delay      = "120s"
    unlimited      = true
  }
}